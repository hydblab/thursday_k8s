도커 스웜
실제 운영을 기준으로 하여 cpu, 메모리 디스크 등이 부족한 경우에는 서버 증설을 하게 됨. 이때 서버를 클러스터로 만들어 자원을 병렬로 증설하는 것이 가성비가 좋다.
번외 ) 단, 그 서버를 살 돈도 없다면 저렴한 하드웨어 여러개를 사거나 서버 인스턴스를 최소한의 성능으로 제공 받아 도커 클러스터를 구축하는 방법도 있을수 있음
여러 서버를 하나의 자원 풀로 만들 때 어려운 점 
새로운 서버 및 컨테이너 추가시 service discovery
어느 서버에 컨테니어를 할당할것인가 (스케쥴러 및 로드 밸런서)
클러스터 내 서버 다운시 high availability 보장 문제
이 모든 것을 해결하기 위한 솔루션! 도커 공식 제공! - 도커 스웜 및 스웜 모드

3.2 스웜 클래식과 도커 스웜모드
여러대의 도커 서버를 하나의 클러스터화 하여 컨테이너를 생성하는 기능 제공. 
특정 도커에 컨테이너를 할당 / 유동적 서버 확장 / 컨테이너 관리 등
서버 클러스터링 입문 단계로 써보기 좋음 
스웜 클래식 : 컨테이너로서의 스웜 (1.6 버전 이후 사용 가능) / 스웜모드 : (1.12 이후 사용 가능)

스웜 클래식 / 스웜모드
스웜 클래식 
- 여러대의 서버를 1개 단일 접근점에서 사용할수 있도록 하는 것이 주 목적
- docker run, docker ps 등 명령어 + 도커 api로 클러스터 서버를 제어하고 관리하는 기능 제공
- 분산 코디네이터, 매니저, 에이전트가 별도 실행되어야 함
-분산 코디네이터 : 새로운 서버의 발견, 클러스터 설정 저장, 데이터 동기화등에 이용
etcd, zookeeper, consul 등이 있음. 
스웜클래식은 대부분 사용 가능하며 스웜모드는 별도 구축을 필요로 하지 않음.
스웜 모드 
- msa 컨테이너를 다루기 위한 클러스터링 기능에 초점
- 같은 컨테이너를 동시에 여러개 생성하여 필요에 따라 컨테이너 수를 조절하고 연결을 분산하는 로드 밸런싱 기능을 지원
- 스웜 클래식에 비해 확장성과 안정성 측면에서 뛰어남
- 클러스터 툴(분산 코디네이터, 매니저, 에이전트등) 이 자체 내장
- 서비스 장애에 대비한 고가용성 및 부하 분산을 위한 로드 밸런싱 기능 내재
	-> 대규모 클러스터 서비스 운용에는 모드가 좋다



3.3 스웜모드
도커 엔진 자체 내장 기능 (설치과정 필요 x) docker info로 정보 확인 가능 (docker info : grep Swarm)
적어도 3대 이상의 서버를 사용해야 테스트 가능 


3.3.1 도커 스웜 모드의 구조
매니저 노드와 워커 노드로 구성
매니저 노드 
워커 노드 관리용 도커 서버 (컨테이너 생성 불가는 아님) (워커노드 역할에 +a)
워커 노드 
실제 컨테이너가 생성되고 관리되는 도커 서버
매니저 노드는 1개 이상 필요, 워커노드는 0개일수도 있음 (매니저 노드가 워커노드까지 할수 있으므로)
일반적으로 매니저 노드를 다중화 하는 것을 권장. (특정 매니저 노드가 다운되더라도 정상적으로 클러스터가 유지되기 위해) (성능상 이점은 없음 오히려 많으면 느려짐 데이터 싱크 과정에서 overhead가 발생)
매니저 노드의 절반이상 장애가 생겨 정상 동작이 어려워지는 경우 클러스터 운영이 중단됨.> 네트워크 파티셔닝 현상이 발생한 경우 짝수개 일 때는 운영이 중단될수도 있지만 홀수개인 경우 쿼럽 매니저에서 운영을 계속 할 수 있기 때문에 홀수개 구성이 권장된다.
네트워크 파티셔닝 현상: 네트 워크 장치 오류등으로 인해 네트워크가 독립적인 서브넷으로 나뉘어지는것
split brain 모든 파티션이 스스로를 primary로 인식하여 데이터 문제 발생 가능
쿼럼 : 정족수. split brain 이슈 발생시 투표를 진행
클러스터 쿼럼 작동 방식
노드가 실패하거나 일부 노드 하위 집합이 다른 하위 집합과의 접촉을 잃으면 생존 노드가 온라인 상태를 유지하기 위해 해당노드가 클러스터의 대부분을 구성하는지 확인해야 합니다. 확인할 수 없는 경우 오프라인으로 전환됩니다.
그러나 대부분의 개념은 클러스터의 총 노드 수가 홀수인 경우에만 명확하게 작동합니다(예: 5개 노드 클러스터의 노드 3개). 
따라서 노드 수가 짝수인 클러스터의 경우 
클러스터에서 총 투표 수를 홀수로 만들 수 있는 두 가지 방법이 있습니다.

첫째,  미러링 모니터 서버가 없으면 한 노드의 투표가 0이 됩니다(필요에 따라 자동으로 발생).
살아남은 노드가 대다수인지 성공적으로 확인할 때마다 대다수 의 정의는 생존자 중 한 명입니다. 이렇게 하면 클러스터가 한 노드, 다른 노드, 다른 노드 등을 잃을 수 있습니다. 연속 실패 후 조정되는 총 투표 수 에 대한 이 개념을 동적 쿼럼이라고 합니다.
(https://learn.microsoft.com/ko-kr/azure-stack/hci/concepts/quorum#cluster-quorum-overview)
(그냥 몰라서…)

3.3.2 도커 스웜 모드 클러스터 구축

매니저 노드 1 워커노드 2로 구성한 케이스를 기준으로 하여 예제 구성
기본 시작 cmd :  docker swarm init —advertise-addr ip 주소(매니저 노드 ip)
> swam initialized : current node () is now a manager.
> docker swarm join \ –token 

—advertise-addr : 매니저 노드에 어느 아이피로 접근해야할지 타 노드에 알려주는 역할 (public ip로 써야함)
docker swarm join 에 나오는 토큰값으로 새로운 노드를 해당 스웜 클러스터에 추가할수 있음.
> 워커노드로 들어가 docker swarm join \ –token ~~ 하면 워커 노드가 해당 스웜 클러스터에 추가됨
> docker node ls로 확인 가능
매니저 노드가 다수인 경우 매니저 노드와 리더 노드로 구분되며 리더 매니저 노드는 모든 매니저 노드에 대한 동기화 및 관리를 담당하므로 항상 작동상태여야 함. 만약 리더 매니저 노드에 장애가 발생하는 경우 새로운 리더를 선출 (raft consensus 알고리즘 - etcd 에서 만듬) 
> 매니저 모드를 추가하려면 docker swarm join-token manager 라고 해서 매니저 노드 추가용 토큰을 따로 받아야 한다.
> 토큰은 보안을 위해 주기적으로 변경하는게 좋음
> 토큰 갱신 docker swarm join-token –rotate manager / worker 로 변경 가능.(매니저 노드에서만)
> 추가된 워커노드를 제거하려면 해당 노드에서 > docker swarm leave 를 통해 나올수 있다. 
이경우 매니저 노드에서도 삭제를 따로 해줘야 한다. > docker node rm (name)
> 추가된 매니저 노드를 제거하려면 > docker swarm leave –force 를 통해 삭제 가능. 이 경우 저장되어있던 클러스터 정보도 날아가므로 주의.
> 매니저 노드가 1개 뿐일때 해당 매니저 노드를 제거하면 스웜 클러스터 사용 불가 상태가 된다.
> 워커 노드를 매니저 노드로 승진 > docker node promote
> 매니저 노드를 워커 노드로 > docker node demote 매니저 노드 1개면 사용 불가, 리더 매니저 노드인 경우 다른 매니저 노드중 새로운 리더 선출

3.3.3 스웜모드 서비스
3.3.3.1 스웜모드 서비스 개념
서비스란 : 같은 이미지에서 생성된 컨테이너의 집합. 스웜모드 제어 단위..
서비스 제어시 전 컨테이너에서 동일 명령이 수행됨.
1개 이상 컨테이너 존재. 개별 컨테이너를 task라 호칭

예제 )
전제 - 우분투 이미지로 서비스 생성, 컨테이너 3개 설정. 
> 이 경우 스웜 스케쥴러가 서비스 정의에 따라 컨테이너를 할당할 노드를 선정, 컨테이너를 분산하여 할당합니다. 3개의 컨테이너가 존재한다고 가정할때, 개별노드마다 컨테이너가 할당 될 수도 있고 아닐수도 있습니다. 
이처럼 함께 생성된 컨테이너를 레플리카 라고 하며 스웜은 서비스에 설정된 레플리카 수만큼 활성화된 컨테이너가 스웜 클러스터 내에 존재하도록 새로운 레플리카를 생성함.
> 롤링 업데이트 : 여러개의 서버, 컨테이너등으로 구성된 클러스터에서 설정이나 데이터를 변경하기 위해 하나씩 재시작하는 것.다운 타임 최소화 및 지속적인 서비스 보장

3.3.3.2 서비스 생성
> 명령어는 모두 매니저 노드에서만 사용 가능함
> 서비스내 컨테이너는 detached 모드, -d 옵션을 사용할수 있는 이미지를 사용해야함.

첫번쨰 서비스 생성 : 
> docker service create \ ubuntu :14.04 \ /bin/sh -c ‘while true; do echo hello world; sleep 1; done
(서비스를 만들고 hello world를 찍은 후 종료) (while true 는 왜 들어가는지? do echo hello world만 하면 문제가 있나?
(create ubuntu 를 한 경우에는 프로세스가 없어서 무한 생성함)
이 경우 이름을 정의 하지 않았으므로 무작위 설정됨

생성된 서비스는 
> docker service ls 
> docker service ps [서비스 이름]
로 확인가능

삭제는 > docker service rm [서비스 이름]

private 이미지 등을 사용한 경우 매니저 노드에서 로그인하여 생성시  –with-registry-auth를 사용하여 매니저 노드에 create 하면 워커노드에서도 로그인 없이 이미지를 받을수 있음.

nginx 웹서버 생성
docker service create —replica 옵션을 주어 외부 포트 80번에 연결 서비스 생성


> 이 경우 각 컨테이너에 ngnix 웹서버가 하나씩 구동되고 있는 것
> 같은 swarm 네트워크 안에 포함된 swarm-worker2를 가정할때, 거기서도 서비스에 접근이 가능하다. 
> docker service create -p 80:80으로 포트 개방을 한 상태로 생각하면 쉽다

>docker service scale 레플리카 셋 수를 조절
> 컨테이너가 다수이더라도 각 80번 포트로 들어온 요청은 위 컨테이너중 1개로 리다이렉트 된다. (‘라운드 로빈’ 방식으로 결정)

글로벌 서비스 생성하기
서비스에는 모드가 있는데
복제 모드 : 레플리카 수를 정의하여 같은 컨테이너를 생성함. 일반적.
글로벌 모드 : 스웜 클러스터 내에서 사용할수 있는 모든 노드에 컨테이너를 반드시 하나씩 생성.(모니터링을 위한 에이전트 컨테이너 생성등에 활용)
> docker service create –mode global 의 옵션을 설정하여 생성 가능. (없으면 기본 복제 모드)

3.3.3.3 스웜모드의 서비스 장애 복구
서비스 컨테이너가 정지하거나, 특정 노드가 다운되는 경우 매니저가 새로운 컨테이너를 자동으로 생성하여 복구함.
특정 서비스 중지 시키는 경우
> docker service rm [특정 서비스 이름]
> docker service ps 
를 하는 경우 지운 컨테이너 대신 다른 컨테이너가 생성된 것을 확인 가능





\_ 동작이 멈춘 컨테이너를 의미. 서비스에서 컨테이너의 변경기록을 나타냄
특정 노드 다운된 경우


3개중 워커 노드 1개를 강제 중지. 

이 경우 해당 노드에 있던 컨테이너가 중지되고 매니저 노드에 해당 컨테이너의 레플리카가 생성됨.
단 다시 엔진을 재가동하더라도 중단된 myweb.2가 가동되진 않는다. scale 명령어를 통해 수를 줄였다 다시 늘려야 가능.

3.3.3.4 서비스 롤링 업데이트

>docker service update –image [] [] (도커 이미지 업데이트 하는 법)

> 서비스를 생성하는 시점에서 롤링 업데이트 정보를 설정 할수 있다.

레플리카 4개, 이름, 업데이트 단위 주기, 한번에 업데이트를 병렬로 수행할 컨테이너 갯수 제한
만약 중간에 중단되는 경우.
–update -failure-action 옵션을 continue로 지정해 에러가 발생해도 계속 진행하도록 할수 있음.

3.3.3.5 서비스 컨테이너에 설정 정보 전달 (config, secret)
d어플리케이션을 외부에 서비스 하는 경우 > 설정파일등이 컨테이너 내부에 있어야 함.
이때 설정파일이 이미지에 포함되면 확장성과 유연성이 떨어진다.
> 이를 위해 환경 변수를  사용하거나 볼륨 컨테이너 등을 활용
단 스웜의 경우 설정 파일을 호스트마다 마련하는 것은 비효율 > 스웜 자체적으로 secret, config 기능을 제공
secret : 비밀번호, 인증서키 등 암호화가 필요한 데이터 전송시
config : 레지스트리 설정 파일과 같은 암호화가 필요없는 설정값에 대해 사용

secret 사용
>echo [암호값] | docker secret create [키] 
 이때 생성된 secret 값은 실제 값을 확인할수 없음. 
매니저 노드간에 암호화된 상태로 저장. 메모리 저장 key 이기 때문에 서비스 컨테이너 삭제시 함께 삭제
단점 : 컨테이너 내부 어플리케이션이 특정 경로로 파일 값을 참조하도록 설계 필요
config 사용
> docker config create [이름] [파일등 임력값]
config 는 inspect config로 data를 볼수 있다. (인코딩 되어있으므로 디코딩하여 확인 가능)

3.3.3.6 도커 스웜 네트워크
스웜모드는 여러개의 엔진에 컨테이너를 분산하므로 개별 도커의 네트워크가 묶인 네트워크 풀 및 라우팅이 필요.
스웜모드 자체 내장 네트워크 드라이버 사용 가능.

* ingress 네트워크 
스웜 클러스터 생성시 자동 생성
스웜모드에서만 유효
어느 스웜 노드에 접근하더라도 서비스내 전체 컨테이너에 접근할수 있도록 하는 라우팅 메시를 구성함.

물론 스웜 모드에서 해당 네트워크 방식을 쓰지 않고 publish 명령어 수행시 호스트 포트를 직업 컨테이너에 연결하여 사용 할수도 있음.
단, 이 경우 어느 호스트에 컨테이너가 생성될지 알수 없어 포트 및 서비스 관리가 어려워진다.

오버레이 네트워크
여러개의 도커 데몬을 하나의 네트워크 풀로 만드는 네트워크 가상화 기술.
도커에 해당 네트워크 적용시 여러개 도커데몬에 존재하는 컨테이너가 서로 통신이 가능
개별 스웜 노드에 할당된 컨테이너가 오버레이 네트워크의 서브넷에 해당하는 ip 를 할당 받고, 해당 ip로 통신
클러스터 내 한 노드에서 실행되면 전체 자동 적용. 각 노드가 네트워크를 사용하는 서비스 컨테이너를 할당 받을때 적용됨.
docker_gwbridge 네트워크
외부로 나가는 통신 및 오버레이 네트워크의 트레픽 종단점 역할을 담당
사용자 정의 오버레이 네트워크
서브넷 설정 가능.
이부분 이해가 안됨

3.3.3.6 서비스 디스커버리
스웜모드는 서비스의 이름으로 해당 서비스를 제공하는 서비스 컨테이너에 모두 접근이 가능함 (특정 컨테이너의 감지가 불필요)
서비스별 virtual ip가 있음. 해당 네이밍에 따라 dns는 호스트 네임을 ip로 변환하고 해당 ip는 컨테이너의 네트워크 네임 스페이스 내부에서 실제 서비스의 컨테이너 ip로 포워딩. 
3.3.3.7 스웜모드 볼륨
호스트와 디렉터리를 공유하는 경우 / 도커 볼륨을 사용하는 경우 로 구분
스웜모드에서는 서비스를 생성하는 시점에 결정해야함.

volume 타입의 볼륨 생성
도커 볼륨을 사용하는 서비스 생성시
> docker service create –name [name]  –mount type=volume, source=[], target=[]
타입으로 지정, source = 사용할 볼륨, target = 마운트될 디렉토리 위치
source 기준으로 동일 네이밍의 볼륨이 있으면 그대로 사용.지정하지 않은경우 임의의 16진수로 랜덤 생성
볼륨 옵션에 volume-nocopy  : 컨테이터 파일이 볼륨에 복사되지 않도록 설정가능
(서비스 컨테이너에서 target 위치에  파일이 이미 존재 하는 경우, 해당 파일이 볼륨에 복사 된 후 호스트에 공간을 차지하게됨. 해당 사항 방지용)
bind 타입의 볼륨 생성
host와 디렉토리 공유하는 경우 (공유될 호스트 디렉토리 설정 필요. source 옵션을 반드시 명시)
> docker service create –name [name]  –mount type=bind, source=[호스트 디렉토리 위치], target=[마운트될 컨테이너 디렉토리 위치]
스웜 모드에서 볼륨의 한계정
스웜 클러스터에서 볼륨을 사용하기 위해서는 모든 노드가 볼륨 데이터를 가져야 함.
(스케쥴러가 컨테이너 할당시 어느 노드에 할당하더라도 서비스에 정의된 볼륨을 사용할수 있어야 하기 때문에) 
> 해당 한계점을 해결하기 위해 Persistant Storage를 사용
 호스트와 컨테이너와 별개로 독립되어 외부에 존재하는 스토리지. 네트워크로 마운트 가능. 단 자체 제공 기능이 아니기 때문에 서드 파티 플러그인을 사용하거나, nfs, dfs등을 별도로 구성해야 함.

	> 그외에 각 노드 별로 label을 붙여 서비스에 제한을 거는 방법이 있음. 
	 (서비스 동작에 필요한 볼륨이 있는 노드에만 컨테이너를 할당하도록 하는 방법)

3.3.4 도커 스웜 모드 노드 다루기
3.3.4.1 노드 availiability 변경
노드의 availability 상태는 docker node ls로 확인 가능
Active 상태 : 새로운 노드가 스웜 클러스터에 추가될때 기본 상태. 서비스의 컨테이너를 할당 받을 수 있음. 
docker node update –availability active [컨테이너] : active로 변경하는 명령어 
Drain : 컨테이너를 중지하고 추가할당받지 않는 상태. 일반적으로 매니저 노드에 설정.
docker node update –availability drain [컨테이너] : drain상태로 변경하는 명령어 
중지된 컨테이너들은 active 노드에 재할당. 
Pause : 컨테이너 추가 할당은 받지 않으나 실행중인 컨테이너가 중지되지는 않는 상태.
3.3.4.2 노드 라벨 추가

키-값 형태로 키값으로 노드를 구별
> service create [] label=[*] > 특정 라벨이 존재하는 노드 기준으로 컨테이너 생성 제한 가능
볼륨 뿐 아니라 네트워크나 지역등 다양한 제한에 활용 가능.
노드 라벨 추가하기
>docker node update –label-add key=value
inspect 명령어로 확인 가능
서비스 제약 설정
- node.labels 제약
> docker service create –name [] –constraint ‘node.lables.key == value’ 
제한에 부합하는 노드가 없는 경우 컨테이너는 생성되지 않음.
- node.id 제약
아예 id로 컨테이너 생성 노드를 지정. 이경우 id 풀로 입력해야함. (안쓸것 같다)
- node.hostname, node.role 제약
클러스터에 등록된 호스트 명 및 역할로 제한 조건 설정 가능
node.role != manager 같은 형식으로 사용
- engine.lables 제약
도커 데몬 자체에 라벨을 설정 (도커데몬 실행 옵션 변경)

